{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad2fd13e-64a6-4282-85f8-6fd169072b1a",
   "metadata": {},
   "source": [
    "# Получение структурированного вывода\n",
    "\n",
    "Получение данных, сгенерированных LLM, в виде структур формата JSON значительно упрощает их хранение и обработку.\n",
    "\n",
    "И хотя модели GigaChat не поддерживают работу в режиме принудительной генерации JSON (т.н. *JSON mode*), существуют способы получить от них данные в структурированном формате.\n",
    "\n",
    "В этом разделе вы узнаете как получить структурированный вывод от моделей GigaChat с помощью LangChain-метода `.with_structured_output()` или парсеров."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edb10e8-cd95-445a-b9b3-e4259f7b58ef",
   "metadata": {},
   "source": [
    "## Подготовка к работе\n",
    "\n",
    "Для работы примеров установите необходимые зависимости и инициализируйте GigaChat.\n",
    "\n",
    "### Установка зависимостей\n",
    "\n",
    "Установите библиотеку langchain-gigachat:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7e1f627-2917-4d29-956a-115ae629f2d4",
   "metadata": {},
   "source": [
    "pip install langchain-gigachat python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a710217d-4821-4ce3-b54d-d19ddd7c9cd6",
   "metadata": {},
   "source": [
    "### Инициализация GigaChat\n",
    "\n",
    "Для работы с моделями GigaChat, нужно передать ключ авторизации GigaChat API.\n",
    "\n",
    "Ключ можно указать в переменной среды `GIGACHAT_CREDENTIALS`, заданной в файле `.env` или созданной с помощью команды:\n",
    "\n",
    "```sh\n",
    "export GIGACHAT_CREDENTIALS=ключ_авториазации\n",
    "```\n",
    "\n",
    "При инициализации проверяется наличие переменной среды `GIGACHAT_CREDENTIALS` с заданным ключом авторизации GigaChat API.\n",
    "Если переменная отсутствует, вы сможете указать ключ в поле **Введите ключ авторизации GigaChat API**.\n",
    "\n",
    "О способах авторизации и поддерживаемых переменных среды — в [README библиотеки gigachat](https://github.com/ai-forever/gigachat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028dc708-b0a9-4132-be04-9e2f582c0f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "from langchain_gigachat.chat_models.gigachat import GigaChat\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "if \"GIGACHAT_CREDENTIALS\" not in os.environ:\n",
    "    os.environ[\"GIGACHAT_CREDENTIALS\"] = getpass.getpass(\"Введите ключ авторизации GigaChat API: \")\n",
    "\n",
    "model = GigaChat(\n",
    "    model=\"GigaChat-2-Max\",\n",
    "    verify_ssl_certs=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552d6954-342f-4c9d-abc7-77aabb72a59c",
   "metadata": {},
   "source": [
    "## Использование `.with_structured_output()`\n",
    "\n",
    "Метод `.with_structured_output()` принимает на вход схему с названиями полей, типами и описанием данных, которые должна вернуть модель.\n",
    "Схема данных может быть описана в виде Pydantic- и TypedDict-классов, или JSON Schema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05255513-907e-48c9-9d87-07d6ce3b0032",
   "metadata": {},
   "source": [
    "### Описание вывода с помощью Pydantic-класса\n",
    "\n",
    "Модели GigaChat могут возвращать Pydantic-объекты.\n",
    "Для этого при вызове метода нужно передать схему данных в виде Pydantic-класса.\n",
    "\n",
    "Преимущество использования Pydantic-классов в том, что Pydantic автоматически провалидирует сгенерированный вывод.\n",
    "Так, если в ответе модели отсутствуют обязательные поля и указаны неверные типы данных, Pydantic вернет ошибку.\n",
    "\n",
    "При описании структуры с помощью Pydantic-класса важно дать понятное название и подробное описание как самому классу, так и его аттрибутам.\n",
    "Все эти данные будут использованы в промпте при отправке запроса в модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7348f3c-0dea-4125-9e3e-af82a208233a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Book(title='1984', author='George Orwell', language='English')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Pydantic \n",
    "class Book(BaseModel):\n",
    "    \"\"\"Книга, которая нужна пользователю\"\"\"\n",
    "    title: str = Field(description=\"Название книги\")\n",
    "    author: Optional[str] = Field(\n",
    "        default=\"неизвестен\", description=\"Автор книги\"\n",
    "    )\n",
    "    language: Optional[str] = Field(\n",
    "        default=\"любой\", description=\"Язык написания книги\"\n",
    "    )\n",
    "\n",
    "\n",
    "structured_llm = model.with_structured_output(Book)\n",
    "\n",
    "structured_llm.invoke(\"Найди '1984' Оруэлла в английском оригинале\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f19ef27-fd13-4f17-a16a-e4b347fad8a2",
   "metadata": {},
   "source": [
    "###  Описание вывода с помощью TypedDict\n",
    "\n",
    "Если вам не нужно явно валидировать ответ модели, вы можете описать схему вывода с помощью класса TypedDict.\n",
    "\n",
    "При этом можно использовать специальный синтаксис `Annotated[...]`, который поддерживает LangChain.\n",
    "С его помощью вы можете задать описания полей, а также указать значения по умолчанию.\n",
    "\n",
    "> [!NOTE]\n",
    "> Значения по умолчанию используются только при определении схемы, которая передается в модель.\n",
    "> Если модель не сгенерирует значение по умолчанию, оно не будет заполнено автоматически."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe37646c-f88b-4ed3-9131-bab9c3a6e433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 'Толкин', 'language': 'английский', 'title': 'Властелин колец'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "\n",
    "# TypedDict\n",
    "class Book(TypedDict):\n",
    "    \"\"\"Книга, которая нужна пользователю\"\"\"\n",
    "    title: Annotated[str, ..., \"Название книги\"]\n",
    "\n",
    "    # Также можно указать title следующим образом:\n",
    "\n",
    "    # title: str                    # без значений по умолчанию и описания\n",
    "    # title: Annotated[str, ...]    # без значений по умолчанию и описания\n",
    "    # title: Annotated[str, \"foo\"]  # без значением по умолчанию, но без описания\n",
    "    \n",
    "    author: Annotated[Optional[str], \"неизвестен\", \"Автор книги\"]\n",
    "    language: Annotated[Optional[str], \"любой\", \"Язык написания книги\"]\n",
    "\n",
    "structured_llm = model.with_structured_output(Book)\n",
    "\n",
    "structured_llm.invoke(\"Ищу 'Властелин колец' Толкина на английском\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c13c2b-ee63-4ff7-a266-dcec617b8069",
   "metadata": {},
   "source": [
    "### Описание вывода с помощью JSON Schema\n",
    "\n",
    "Кроме Pydantic- и TypedDict-классов, для описания требуемого вывода модели можно использовать JSON Schema.\n",
    "Такой подход не требует дополнительного импорта или классов, и наглядно показывает как документируются параметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe484ca2-48cb-46a1-820d-f60c7f78e73f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 'Стивен Хокинг',\n",
       " 'language': 'русский',\n",
       " 'title': 'Краткая история времени'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_schema = {\n",
    "          \"name\": \"book\",\n",
    "          \"description\": \"Книга, которая нужна пользователю\",\n",
    "          \"parameters\": {\n",
    "              \"properties\": {\n",
    "                  \"title\": {\n",
    "                      \"description\": \"Название книги\",\n",
    "                      \"type\": \"string\"\n",
    "                  },\n",
    "                  \"author\": {\n",
    "                      \"description\": \"Автор книги\",\n",
    "                      \"type\": \"string\",\n",
    "                      \"deafault\": \"неизвестен\"\n",
    "                  },\n",
    "                  \"language\": {\n",
    "                      \"description\": \"Язык написания книги\",\n",
    "                      \"type\": \"string\"\n",
    "                  }\n",
    "              },\n",
    "              \"required\": [\n",
    "                  \"title\",\n",
    "              ],\n",
    "              \"type\": \"object\"\n",
    "          },\n",
    "      }\n",
    "structured_llm = model.with_structured_output(json_schema)\n",
    "\n",
    "structured_llm.invoke(\"Нужна 'Краткая история времени' Хокинга на русском\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3518c55-e018-4000-872c-270cda96ec0b",
   "metadata": {},
   "source": [
    "### Добавление примеров (few-shot)\n",
    "\n",
    "При работе со сложными схемами передайте в модель несколько примеров (*few-shots*) того, каким должен быть ожидаемый вывод.\n",
    "Примеры можно передать в системном промпте или в списке вызовов инструментов (функций) `tool_calls[]`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685386a6-1cc0-4627-b074-426d5cc7304b",
   "metadata": {},
   "source": [
    "\n",
    "#### Примеры в системном промпте\n",
    "\n",
    "Примеры запросов пользователя и ожидаемого структурированного вывода можно передать в системном промпте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d084d574-83ee-449c-babf-dbb08e1e3a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 'Карлос Руис Сафон', 'language': 'испанский', 'title': 'Тень ветра'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system = \"\"\"Верни из запроса пользователя информацию о книге, которую он хочет найти. Ответ должен содержать title, author и language. \n",
    "\n",
    "example_user: Мне нужна книга 'Война и мир'\n",
    "example_assistant: {{\"title\": \"Война и мир\", \"author\": \"неизвестен\", \"language\": \"любой\"}}\n",
    "\n",
    "example_user: Нужна сказка 'Маленький принц' Антуана де Сент-Экзюпери на французском.\n",
    "example_assistant: {{\"title\": \"Маленький принц\", \"author\": \"Антуан де Сент-Экзюпери\", \"language\": \"французский\"}}\n",
    "\n",
    "example_user: Хочу прочитать 'Сто лет одиночества' Габриэля Гарсиа Маркеса\n",
    "example_assistant: {{\"title\": \"Сто лет одиночества\", \"author\": \"Габриэль Гарсиа Маркес\", \"language\": \"любой\"}}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"{input}\")])\n",
    "\n",
    "few_shot_structured_llm = prompt | structured_llm\n",
    "few_shot_structured_llm.invoke(\"Нужна 'Тень ветра' Карлоса Руиса Сафона на испанском\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b48e46-99da-4ce7-8b59-ccddf78d47f2",
   "metadata": {},
   "source": [
    "#### Примеры как вызовы инструмента (функции)\n",
    "\n",
    "Если для структурирования вывода используется вызов инструментов (функций), вы можете передать примеры вызовов в списке `tool_calls[]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a0e09b-5849-465f-aa59-8b7b0588864b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 'Пушкин', 'language': 'русский', 'title': 'Евгений Онегин'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "\n",
    "examples = [\n",
    "    HumanMessage(\"Мне нужна книга 'Война и мир'\", name=\"example_user\"),\n",
    "    AIMessage(\n",
    "        \"\",\n",
    "        name=\"example_assistant\",\n",
    "        tool_calls=[\n",
    "            {\n",
    "                \"name\": \"book\",\n",
    "                \"args\": {\n",
    "                            \"title\": \"Война и мир\",\n",
    "                            \"author\": \"неизвестен\",\n",
    "                            \"language\": \"любой\"\n",
    "                        },\n",
    "                \"id\": \"1\",\n",
    "            }\n",
    "        ],\n",
    "    ),\n",
    "    # Большинство моделей, поддерживающих работу с инструментами (функциями), ожидают получение сообщений типа ToolMessage после сообщения типа AIMessage с вызовами инструментов.\n",
    "    ToolMessage(\"\", tool_call_id=\"1\"),\n",
    "    HumanMessage(\"Нужна сказка 'Маленький принц' Антуана де Сент-Экзюпери на французском.\", name=\"example_user\"),\n",
    "    AIMessage(\n",
    "        \"\",\n",
    "        name=\"example_assistant\",\n",
    "        tool_calls=[\n",
    "            {\n",
    "                \"name\": \"joke\",\n",
    "                \"args\": {\n",
    "                    \"title\": \"Маленький принц\",\n",
    "                    \"author\": \"Антуан де Сент-Экзюпери\",\n",
    "                    \"language\": \"французский\"\n",
    "                },\n",
    "                \"id\": \"2\",\n",
    "            }\n",
    "        ],\n",
    "    ),\n",
    "    ToolMessage(\"\", tool_call_id=\"2\"),\n",
    "    HumanMessage(\"Хочу прочитать 'Сто лет одиночества' Габриэля Гарсиа Маркеса\", name=\"example_user\"),\n",
    "    AIMessage(\n",
    "        \"\",\n",
    "        tool_calls=[\n",
    "            {\n",
    "                \"name\": \"joke\",\n",
    "                \"args\": {\n",
    "                    \"title\": \"Сто лет одиночества\",\n",
    "                    \"author\": \"Габриэль Гарсиа Маркес\",\n",
    "                    \"language\": \"любой\"\n",
    "                },\n",
    "                \"id\": \"3\",\n",
    "            }\n",
    "        ],\n",
    "    ),\n",
    "    ToolMessage(\"\", tool_call_id=\"3\"),\n",
    "]\n",
    "system = \"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system), (\"placeholder\", \"{examples}\"), (\"human\", \"{input}\")]\n",
    ")\n",
    "few_shot_structured_llm = prompt | structured_llm\n",
    "few_shot_structured_llm.invoke({\"input\": \"Нужен 'Евгений Онегин' Пушкина в оригинале на русском\", \"examples\": examples})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634b279f-3f4b-44d2-82f5-95fef676071e",
   "metadata": {},
   "source": [
    "### Получение необработанного вывода\n",
    "\n",
    "Большие языковые модели не всегда качественно генерируют структурированные данные.\n",
    "Это может быть особенно заметно при работе со сложными схемами.\n",
    "\n",
    "Чтобы избежать возможных проблем, вы можете самостоятельно разбирать необработанный ответ модели с помощью собственного или встроенного парсера LangChain.\n",
    "\n",
    "Для получения необработанного вывода передайте параметр `include_raw=True` при вызове метода `.with_structured_output()`.\n",
    "В этом случае метод вернет необработанный вывод, результат парсинга и все возникшие ошибки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b283611-d15e-42f6-9389-10db1f17453a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw': AIMessage(content='', additional_kwargs={'function_call': {'name': 'Book', 'arguments': {'author': 'Иоганн Вольфганг Гёте', 'language': 'русский', 'title': 'Фауст'}}, 'functions_state_id': '7640eb48-de06-4794-b91c-895ab69ea8f4'}, response_metadata={'token_usage': {'prompt_tokens': 63, 'completion_tokens': 43, 'total_tokens': 106, 'precached_prompt_tokens': 48}, 'model_name': 'GigaChat-2-Max:2.0.28.02', 'x_headers': {'x-request-id': 'a455038c-c222-45ce-b849-3fe727181a72', 'x-session-id': '1ce13963-0697-4b7c-9cc8-6d6d8bb99e2a', 'x-client-id': None}, 'finish_reason': 'function_call'}, id='a455038c-c222-45ce-b849-3fe727181a72', tool_calls=[{'name': 'Book', 'args': {'author': 'Иоганн Вольфганг Гёте', 'language': 'русский', 'title': 'Фауст'}, 'id': '99e5d0c9-b24a-40c1-9df0-d56ab838507b', 'type': 'tool_call'}]),\n",
       " 'parsed': {'author': 'Иоганн Вольфганг Гёте',\n",
       "  'language': 'русский',\n",
       "  'title': 'Фауст'},\n",
       " 'parsing_error': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm = model.with_structured_output(Book, include_raw=True)\n",
    "\n",
    "structured_llm.invoke(\"Нужен 'Фауст' Гёте в переводе на русский\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe4aba3-cde6-4399-8313-14c9caae77b4",
   "metadata": {},
   "source": [
    "## С помощью парсинга вывода модели\n",
    "\n",
    "При работе со сложными схемами данных модели не всегда могут возвращать удовлетворительный ответ.\n",
    "\n",
    "Для предотвращения таких ситуаций, вы можете передать в системном промпте инструкции о том, какой формат ответа требуется от модели, после чего самостоятельно разобрать ответ модели.\n",
    "Для разбора ответа и извлечения структурированных данных из необработанного ответа модели вы можете использовать собственный или встроенный парсер LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c17fb0-849b-4ae6-8109-39014c103ab1",
   "metadata": {},
   "source": [
    "### Встроенный парсер `PydanticOutputParser`\n",
    "\n",
    "Для разбора ответа, сгенерированного моделью в соответствии с переданной схемой Pydantic, можно использовать парсер `PydanticOutputParser`, встроенный в LangChain.\n",
    "\n",
    "В пример ниже `format_instructions` добавляется в промпт из метода парсера.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3050698d-c926-450a-96e7-3eae53c86fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Информация о человеке.\"\"\"\n",
    "\n",
    "    name: str = Field(..., description=\"Имя человека\")\n",
    "    height_in_meters: float = Field(\n",
    "        ..., description=\"Рост человека, выраженный в метрах.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class People(BaseModel):\n",
    "    \"\"\"Информация обо всех людях в тексте.\"\"\"\n",
    "\n",
    "    people: List[Person]\n",
    "\n",
    "\n",
    "# Подготовка парсера\n",
    "parser = PydanticOutputParser(pydantic_object=People)\n",
    "\n",
    "# Промпт\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user query. Wrap the output in `json` tags\\n{format_instructions}\",\n",
    "        ),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ").partial(format_instructions=parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d442ffa-6183-4365-9888-5e725e1109ea",
   "metadata": {},
   "source": [
    "Демонстрация данных, которые передаются в модель.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c528e07-51fb-404c-93a2-c3d51688d8d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: Answer the user query. Wrap the output in `json` tags\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"$defs\": {\"Person\": {\"description\": \"Информация о человеке.\", \"properties\": {\"name\": {\"description\": \"Имя человека\", \"title\": \"Name\", \"type\": \"string\"}, \"height_in_meters\": {\"description\": \"Рост человека, выраженный в метрах.\", \"title\": \"Height In Meters\", \"type\": \"number\"}}, \"required\": [\"name\", \"height_in_meters\"], \"title\": \"Person\", \"type\": \"object\"}}, \"description\": \"Информация обо всех людях в тексте.\", \"properties\": {\"people\": {\"items\": {\"$ref\": \"#/$defs/Person\"}, \"title\": \"People\", \"type\": \"array\"}}, \"required\": [\"people\"]}\n",
      "```\n",
      "Human: Анне 23 года, ее рост 6 футов.\n"
     ]
    }
   ],
   "source": [
    "query = \"Анне 23 года, ее рост 6 футов.\"\n",
    "\n",
    "print(prompt.invoke({\"query\": query}).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "966dfa2d-3bcc-4c56-8428-d5ebce2936a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "People(people=[Person(name='Анна', height_in_meters=1.83)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3e44dd-204d-4017-a7ff-9141418372bb",
   "metadata": {},
   "source": [
    "### Собственный парсер\n",
    "\n",
    "Для разбора ответа модели вы также можете использовать собственный парсер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efe8535-045d-4e23-96ad-bd3e3ad038b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:31: SyntaxWarning: invalid escape sequence '\\`'\n",
      "<>:32: SyntaxWarning: invalid escape sequence '\\`'\n",
      "<>:41: SyntaxWarning: invalid escape sequence '\\`'\n",
      "<>:31: SyntaxWarning: invalid escape sequence '\\`'\n",
      "<>:32: SyntaxWarning: invalid escape sequence '\\`'\n",
      "<>:41: SyntaxWarning: invalid escape sequence '\\`'\n",
      "C:\\Users\\Anastasia\\AppData\\Local\\Temp\\ipykernel_19248\\3397104921.py:31: SyntaxWarning: invalid escape sequence '\\`'\n",
      "  \"соответствует заданной схеме: \\`\\`\\`json\\n{schema}\\n\\`\\`\\`. \"\n",
      "C:\\Users\\Anastasia\\AppData\\Local\\Temp\\ipykernel_19248\\3397104921.py:32: SyntaxWarning: invalid escape sequence '\\`'\n",
      "  \"Обязательно заключите ответ в теги \\`\\`\\`json и \\`\\`\\`\"\n",
      "C:\\Users\\Anastasia\\AppData\\Local\\Temp\\ipykernel_19248\\3397104921.py:41: SyntaxWarning: invalid escape sequence '\\`'\n",
      "  \"\"\"Extracts JSON content from a string where JSON is embedded between \\`\\`\\`json and \\`\\`\\` tags.\n",
      "C:\\Users\\Anastasia\\AppData\\Local\\Temp\\ipykernel_19248\\3397104921.py:36: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  ).partial(schema=People.schema())\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Информация о человеке.\"\"\"\n",
    "\n",
    "    name: str = Field(..., description=\"Имя человека\")\n",
    "    height_in_meters: float = Field(\n",
    "        ..., description=\"Рост человека, выраженный в метрах.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class People(BaseModel):\n",
    "    \"\"\"Информация обо всех людях в тексте.\"\"\"\n",
    "\n",
    "    people: List[Person]\n",
    "\n",
    "\n",
    "# Промпт\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Ответьте на запрос пользователя. Выведите свой ответ в формате JSON, который \"\n",
    "            \"соответствует заданной схеме: \\`\\`\\`json\\n{schema}\\n\\`\\`\\`. \"\n",
    "            \"Обязательно заключите ответ в теги \\`\\`\\`json и \\`\\`\\`\"\n",
    "        ),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ").partial(schema=People.schema())\n",
    "\n",
    "\n",
    "# Собственный парсер\n",
    "def extract_json(message: AIMessage) -> List[dict]:\n",
    "    \"\"\"Extracts JSON content from a string where JSON is embedded between \\`\\`\\`json and \\`\\`\\` tags.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The text containing the JSON content.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of extracted JSON strings.\n",
    "    \"\"\"\n",
    "    text = message.content\n",
    "    # Регулярное выражение для обнаружения блоков JSON.\n",
    "    pattern = r\"\\`\\`\\`json(.*?)\\`\\`\\`\"\n",
    "\n",
    "    # Обнаружение всех неперекрывающихся совпадения регулярного выражения в строке.\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "\n",
    "    # Вернуть список обнаруженных строк JSON, после удаления любых начальных или конечных пробелов.\n",
    "    try:\n",
    "        return [json.loads(match.strip()) for match in matches]\n",
    "    except Exception:\n",
    "        raise ValueError(f\"Failed to parse: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99689343-915c-4be3-8163-b3973ecda72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: Ответьте на запрос пользователя. Выведите свой ответ в формате JSON, который соответствует заданной схеме: \\`\\`\\`json\n",
      "{'$defs': {'Person': {'description': 'Информация о человеке.', 'properties': {'name': {'description': 'Имя человека', 'title': 'Name', 'type': 'string'}, 'height_in_meters': {'description': 'Рост человека, выраженный в метрах.', 'title': 'Height In Meters', 'type': 'number'}}, 'required': ['name', 'height_in_meters'], 'title': 'Person', 'type': 'object'}}, 'description': 'Информация обо всех людях в тексте.', 'properties': {'people': {'items': {'$ref': '#/$defs/Person'}, 'title': 'People', 'type': 'array'}}, 'required': ['people'], 'title': 'People', 'type': 'object'}\n",
      "\\`\\`\\`. Обязательно заключите ответ в теги \\`\\`\\`json и \\`\\`\\`\n",
      "Human: Анне 23 года, ее рост 6 футов, а Артему 24 и его рост 6.3 фута.\n"
     ]
    }
   ],
   "source": [
    "query = \"Анне 23 года, ее рост 6 футов, а Артему 24 и его рост 6.3 фута.\"\n",
    "\n",
    "print(prompt.format_prompt(query=query).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "679df3df-85da-4700-be8f-2f78b06f33c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<unknown>:2: SyntaxWarning: invalid escape sequence '\\`'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'people': [{'name': 'Анна', 'height_in_meters': 1.83},\n",
       "   {'name': 'Артем', 'height_in_meters': 1.92}]}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | extract_json\n",
    "\n",
    "chain.invoke({\"query\": query})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
